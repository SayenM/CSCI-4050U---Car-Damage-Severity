{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.data import AUTOTUNE\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH = 32\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    \"data3a/training\", labels=\"inferred\", label_mode=\"int\",\n",
    "    image_size=IMG_SIZE, shuffle=True\n",
    ")\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    \"data3a/validation\", labels=\"inferred\", label_mode=\"int\",\n",
    "    image_size=IMG_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "# (optional) use val as test for now\n",
    "test_ds = val_ds\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# cache/prefetch\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(AUTOTUNE)\n",
    "test_ds  = test_ds.cache().prefetch(AUTOTUNE)\n",
    "\n",
    "# normalize to 0..1\n",
    "normalization = keras.layers.Rescaling(1./255)\n",
    "train_ds_n = train_ds.map(lambda x,y: (normalization(x), y))\n",
    "val_ds_n   = val_ds.map(lambda x,y: (normalization(x), y))\n",
    "test_ds_n  = test_ds.map(lambda x,y: (normalization(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=input_shape\n",
    ")\n",
    "base_model.trainable = False  # start frozen\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=5, restore_best_weights=True\n",
    ")\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"models/vgg16_finetuned_best.keras\",  # NOTE: .keras extension\n",
    "    monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3, verbose=1\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "train_input = train_ds_n_aug if \"train_ds_n_aug\" in globals() else train_ds_n\n",
    "\n",
    "history = model.fit(\n",
    "    train_input,\n",
    "    validation_data=val_ds_n,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, ckpt, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_ft = model.fit(\n",
    "    train_input,\n",
    "    validation_data=val_ds_n,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, ckpt, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds_n, verbose=0)\n",
    "print(f\"Test Acc: {test_acc:.3f}  |  Test Loss: {test_loss:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_ds_n])\n",
    "y_pred_probs = model.predict(test_ds_n, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save the final full Keras model (recommended)\n",
    "model.save(\"models/vgg16_finetuned_final.keras\")   # <-- note the .keras extension\n",
    "\n",
    "# (Optional) also export a TF SavedModel directory for deployment\n",
    "model.export(\"models/vgg16_finetuned_savedmodel\")  # creates a folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# pick the correct history object\n",
    "hist = history_ft if 'history_ft' in globals() else history\n",
    "\n",
    "train_acc = hist.history[\"accuracy\"]\n",
    "val_acc   = hist.history[\"val_accuracy\"]\n",
    "train_loss = hist.history[\"loss\"]\n",
    "val_loss   = hist.history[\"val_loss\"]\n",
    "epochs = np.arange(1, len(train_acc)+1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax[0].plot(epochs, train_acc, label=\"Train\")\n",
    "ax[0].plot(epochs, val_acc,   label=\"Validation\")\n",
    "ax[0].set_title(\"Accuracy\"); ax[0].set_xlabel(\"Epoch\"); ax[0].legend()\n",
    "\n",
    "ax[1].plot(epochs, train_loss, label=\"Train\")\n",
    "ax[1].plot(epochs, val_loss,   label=\"Validation\")\n",
    "ax[1].set_title(\"Loss\"); ax[1].set_xlabel(\"Epoch\"); ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"models/training_curves.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# if you restored best weights via EarlyStopping that's fine.\n",
    "# Otherwise, you can ensure best checkpoint by uncommenting:\n",
    "# from tensorflow import keras\n",
    "# model = keras.models.load_model(\"models/vgg16_finetuned_best.keras\")\n",
    "\n",
    "# Ensure these exist from your earlier cells:\n",
    "# class_names, test_ds_n, model\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_ds_n])\n",
    "y_prob = model.predict(test_ds_n, verbose=0)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(5,5))\n",
    "disp.plot(values_format='d', cmap=\"Blues\", ax=ax2, colorbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"models/confusion_matrix.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-damage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
